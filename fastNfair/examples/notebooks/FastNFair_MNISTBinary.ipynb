{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gf4WtAPAxuXd"
      ],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Install"
      ],
      "metadata": {
        "id": "gf4WtAPAxuXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install git+https://github.com/elizabethnewman/fast-n-fair.git"
      ],
      "metadata": {
        "id": "PNhBrlwxxt4w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Wm-Z-A3yxoP9"
      },
      "outputs": [],
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim\n",
        "from fastNfair.data import gray_to_color, generate_color_mnist_binary, generate_mnist, visualize_color_mnist\n",
        "from fastNfair.objective_functions import ObjectiveFunctionLogisticRegression\n",
        "from fastNfair.regularizers import RegularizerInvariantRisk\n",
        "from fastNfair.training import TrainerSGD, Evaluator\n",
        "import hessQuik.activations as act\n",
        "import hessQuik.layers as lay\n",
        "import hessQuik.networks as net\n",
        "import time\n",
        "\n",
        "evaluator = Evaluator()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device"
      ],
      "metadata": {
        "id": "URIL0kVSxv2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(f'cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print('Device:', device)"
      ],
      "metadata": {
        "id": "4AMhAuNYxqPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate Data\n",
        "\n",
        "TODO: Provide description"
      ],
      "metadata": {
        "id": "kGrdYatt1AzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# https://github.com/facebookresearch/InvariantRiskMinimization/tree/main\n",
        "\n",
        "# number of data points\n",
        "p_train, p_val, p_test = 0.2, 0.1, 0.9\n",
        "n_train, n_val, n_test = 200, 50, 50\n",
        "\n",
        "# generate data\n",
        "(x, y), (x_t, y_t) = generate_mnist(n_train=n_train + n_val, n_test=n_test)\n",
        "\n",
        "\n",
        "# split data\n",
        "x_train, digit_train = x[:n_train], y[:n_train]\n",
        "x_val, digit_val = x[n_train:n_train + n_val], y[n_train:n_train + n_val]\n",
        "x_test, digit_test = x_t, y_t\n",
        "\n",
        "# color data\n",
        "x_train, y_train, s_train = generate_color_mnist_binary(x_train, digit_train, p_train)\n",
        "x_val, y_val, s_val = generate_color_mnist_binary(x_val, digit_val, p_val)\n",
        "x_test, y_test, s_test = generate_color_mnist_binary(x_test, digit_test, p_test)\n",
        "\n",
        "# visualize\n",
        "n = 64\n",
        "visualize_color_mnist((x_train[:n], y_train[:n], s_train[:n]), n_rows=4)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qk5Cc1U51Drt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute correlation between labels and digit\n",
        "corr_digit_train = (1.0 * (y_train == digit_train)).sum() / y_train.numel()\n",
        "corr_attr_train = (1.0 * (y_train == s_train)).sum() / y_train.numel()\n",
        "\n",
        "corr_digit_val = (1.0 * (y_val == digit_val)).sum() / y_val.numel()\n",
        "corr_attr_val = (1.0 * (y_val == s_val)).sum() / y_val.numel()\n",
        "\n",
        "corr_digit_test = (1.0 * (y_test == digit_test)).sum() / y_test.numel()\n",
        "corr_attr_test = (1.0 * (y_test == s_test)).sum() / y_test.numel()\n",
        "\n",
        "print('Correlation of labels and attributes with true digit')\n",
        "print('TRAIN: digit: %0.4f\\tattr: %0.4f' % (corr_digit_train, corr_attr_train))\n",
        "print('VAL:   digit: %0.4f\\tattr: %0.4f' % (corr_digit_val, corr_attr_val))\n",
        "print('TEST:  digit: %0.4f\\tattr: %0.4f' % (corr_digit_test, corr_attr_test))"
      ],
      "metadata": {
        "id": "OmcZDAP26SsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Non-Robust Training"
      ],
      "metadata": {
        "id": "9ELJqyt86QE-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# create linear network\n",
        "my_net = net.NN(net.fullyConnectedNN([x_train.shape[1] * x_train.shape[2] * x_train.shape[3], 20, 10],\n",
        "                                     act=act.tanhActivation()),\n",
        "                lay.singleLayer(10, 1, act=act.identityActivation(), bias=True)\n",
        "                )\n",
        "\n",
        "# create objective function\n",
        "fctn = ObjectiveFunctionLogisticRegression(my_net)\n",
        "\n",
        "# choose optimizer\n",
        "opt = torch.optim.Adam(fctn.parameters(), lr=1e-3)\n",
        "\n",
        "# construct trainer\n",
        "trainer = TrainerSGD(opt, max_epochs=10, batch_size=5,\n",
        "                     regularier=RegularizerInvariantRisk(alpha=0.0))\n",
        "\n",
        "# train!\n",
        "t0 = time.perf_counter()\n",
        "results_train = trainer.train(fctn, (x_train.view(x_train.shape[0], -1), y_train, s_train), (x_val.view(x_val.shape[0], -1), y_val, s_val), (x_test.view(x_test.shape[0], -1), y_test, s_test),\n",
        "                              verbose=True, robust=False, radius=1e1)\n",
        "t1 = time.perf_counter()\n",
        "results_train['total_time'] = t1 - t0\n"
      ],
      "metadata": {
        "id": "GqQq3twE1kyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_eval = evaluator.evaluate(fctn, (x_train.view(x_train.shape[0], -1), y_train, s_train), (x_val.view(x_val.shape[0], -1), y_val, s_val), (x_test.view(x_test.shape[0], -1), y_test, s_test))"
      ],
      "metadata": {
        "id": "YubbFXHe6jiy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Results"
      ],
      "metadata": {
        "id": "-16XbqQQ6iyU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "\n",
        "cm = itemgetter(*('TN', 'FN', 'FP', 'TP'))(results_eval['train']['full']['stats'])\n",
        "metrics.ConfusionMatrixDisplay(np.array(cm).reshape(2, -1)).plot()\n",
        "plt.show()\n",
        "\n",
        "for j in ('full', 's = 0', 's = 1'):\n",
        "    fpr, tpr, auc = itemgetter(*('fpr', 'tpr', 'auc'))(results_eval['train'][j])\n",
        "    plt.plot(fpr, tpr, label=j + ': AUC = %0.4f' % auc)\n",
        "\n",
        "plt.plot(torch.linspace(0, 1, 100), torch.linspace(0, 1, 100), '--', label='rand')\n",
        "\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ynq7rScP6pdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Robust Training"
      ],
      "metadata": {
        "id": "isFXq5oE7NQz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# create linear network\n",
        "my_net = net.NN(net.fullyConnectedNN([x_train.shape[1] * x_train.shape[2] * x_train.shape[3], 20, 10],\n",
        "                                     act=act.tanhActivation()),\n",
        "                lay.singleLayer(10, 1, act=act.identityActivation(), bias=True)\n",
        "                )\n",
        "\n",
        "# create objective function\n",
        "fctn = ObjectiveFunctionLogisticRegression(my_net)\n",
        "\n",
        "# choose optimizer\n",
        "opt = torch.optim.Adam(fctn.parameters(), lr=1e-3)\n",
        "\n",
        "# construct trainer\n",
        "trainer = TrainerSGD(opt, max_epochs=10, batch_size=5,\n",
        "                     regularier=RegularizerInvariantRisk(alpha=0.0))\n",
        "\n",
        "# train!\n",
        "t0 = time.perf_counter()\n",
        "results_train = trainer.train(fctn, (x_train.view(x_train.shape[0], -1), y_train, s_train), (x_val.view(x_val.shape[0], -1), y_val, s_val), (x_test.view(x_test.shape[0], -1), y_test, s_test),\n",
        "                              verbose=True, robust=True, radius=1e1)\n",
        "t1 = time.perf_counter()\n",
        "results_train['total_time'] = t1 - t0\n"
      ],
      "metadata": {
        "id": "BcjocdnS7NQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_eval_robust = evaluator.evaluate(fctn, (x_train.view(x_train.shape[0], -1), y_train, s_train), (x_val.view(x_val.shape[0], -1), y_val, s_val), (x_test.view(x_test.shape[0], -1), y_test, s_test))"
      ],
      "metadata": {
        "id": "jjxCaApG7NQ2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Visualize Results"
      ],
      "metadata": {
        "id": "wKg57sUl7NQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "from operator import itemgetter\n",
        "\n",
        "cm = itemgetter(*('TN', 'FN', 'FP', 'TP'))(results_eval_robust['train']['full']['stats'])\n",
        "metrics.ConfusionMatrixDisplay(np.array(cm).reshape(2, -1)).plot()\n",
        "plt.show()\n",
        "\n",
        "for j in ('full', 's = 0', 's = 1'):\n",
        "    fpr, tpr, auc = itemgetter(*('fpr', 'tpr', 'auc'))(results_eval_robust['train'][j])\n",
        "    plt.plot(fpr, tpr, label=j + ': AUC = %0.4f' % auc)\n",
        "\n",
        "plt.plot(torch.linspace(0, 1, 100), torch.linspace(0, 1, 100), '--', label='rand')\n",
        "\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hOMCn3767NQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fairness Comparison"
      ],
      "metadata": {
        "id": "SPyNFmSu7V_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# comparison of fairness metrics\n",
        "from pprint import pprint\n",
        "print('STANDARD')\n",
        "pprint(results_eval['train']['fairness'])\n",
        "\n",
        "print('ROBUST')\n",
        "pprint(results_eval_robust['train']['fairness'])"
      ],
      "metadata": {
        "id": "ifRw-LP-7XWK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
