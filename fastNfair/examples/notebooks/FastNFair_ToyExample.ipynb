{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Install Packages\n",
    "\n",
    "We need to install the necessary packages and install the Fast-N-Fair github repository."
   ],
   "metadata": {
    "id": "evicPbAvy7zP"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdsoWloDyXXx"
   },
   "outputs": [],
   "source": [
    "personal_access_token = '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'\n",
    "!python -m pip install git+https://$personal_access_token@github.com/elizabethnewman/fast-n-fair.git"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.optim\n",
    "\n",
    "from fastNfair.data import generate_unfair_data, visualize_unfair_data\n",
    "from fastNfair.objective_functions import ObjectiveFunctionLogisticRegression\n",
    "from fastNfair.training import TrainerSGD, Evaluator\n",
    "import hessQuik.activations as act\n",
    "import hessQuik.layers as lay\n",
    "import hessQuik.networks as net\n",
    "\n",
    "# get the evaluator for all methods\n",
    "evaluator = Evaluator()"
   ],
   "metadata": {
    "id": "xRCwMAPyy7Kv"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Data\n",
    "\n",
    "Imagine we have a very strange hiring strategy that depends on two numerical quantities per applicant: the percentage of the day spent in the sun and the percentage of   Anyone who spends a lot of time in the sun and who . \n",
    "\n",
    "Further imagine that we live in a strange world in which all applicants eat either Apples or Bananas (everyone eats one and only one of these fruits).  Because Bananas grow in the summer, Banana eaters naturally prefer to be outside in summer months with more sun, and vice versa for Apple eaters.  Similarly, Apple eaters\n",
    "\n",
    "Mathematically, the data are $\\{(\\mathbf{x}_i,y_i,s_i)\\}$ where $\\mathbf{x}_i\\in\\mathbb{R}^2$ are the scores (GPA, SAT), $y_i\\in \\{0,1\\}$ are the labels (hired or not hired), and $s_i\\in \\{0,1\\}$ are the sensitive attributes (Apples or Bananas).  We construct the data unfairly using the following steps:\n",
    "\n",
    "1. Generate samples of scores $\\mathbf{x}_i$. \n",
    "\n",
    "2. Label $y_i$ each point  based on a prescribed classifier; in our case, above or below the line $y = -x + 1$.\n",
    "\n",
    "3. Randomly give each label a sensitive attribute $s_i$ based on a prescribed percentage; in our case, $50\\%$ of each label is given the attibute $s = 0$.\n",
    "\n",
    "4. Shift the points based on sensitive attribute to make the original classifier unfair as follows:\n",
    "\\begin{align*}\n",
    "\\begin{cases}\n",
    "\\mathbf{x}_i - \\mathbf{u} & y_i = 1 \\text{ and } s_i = 0\\\\\n",
    "\\mathbf{x}_i + \\mathbf{u} & y_i = 0 \\text{ and } s_i = 1\n",
    "\\end{cases}\n",
    "\\end{align*}\n",
    "where $\\mathbf{u}$ is, ideally, orthogonal to the classifier; in this case, $\\mathbf{u} = \\alpha (1,1)^\\top$ for some scalar $\\alpha$ we control.\n",
    "\n",
    "This shift makes it harder to be hired if a person belongs to group $0$ and easier to be hired if a person is in group $1$, based on the original classifier.  "
   ],
   "metadata": {
    "id": "_fYnoUm1jg5b"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# generate data\n",
    "p1, p2, alpha = 0.5, 0.5, 0.1\n",
    "x_train, y_train, s_train = generate_unfair_data(250, p1=p1, p2=p2, alpha=alpha)\n",
    "\n",
    "n_train = 200\n",
    "x_val, y_val, s_val = x_train[n_train:], y_train[n_train:], s_train[n_train:]\n",
    "x_train, y_train, s_train = x_train[:n_train], y_train[:n_train], s_train[:n_train]\n",
    "\n",
    "# test data\n",
    "x_test, y_test, s_test = generate_unfair_data(50, p1=p1, p2=p2, alpha=alpha)\n",
    "\n",
    "\n",
    "visualize_unfair_data((x_train, y_train, s_train), domain=(-0.1, 1.1, -0.1, 1.1))\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "9AdHpw_9jkQQ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Non-Robust Training\n",
    "\n",
    "Here, we train a network without robust optimization."
   ],
   "metadata": {
    "id": "oxSsF0txSCB9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# create linear network\n",
    "my_net = net.NN(lay.singleLayer(2, 1, act=act.identityActivation(), bias=True))\n",
    "\n",
    "# create objective function\n",
    "fctn = ObjectiveFunctionLogisticRegression(my_net)\n",
    "\n",
    "# choose optimizer\n",
    "opt = torch.optim.Adam(fctn.parameters(), lr=1e-2)\n",
    "\n",
    "# construct trainer\n",
    "trainer = TrainerSGD(opt, max_epochs=20)\n",
    "\n",
    "# train!\n",
    "results_train = trainer.train(fctn, (x_train, y_train, s_train), (x_val, y_val, s_val), (x_test, y_test, s_test), \n",
    "                              verbose=True, robust=False)\n"
   ],
   "metadata": {
    "id": "IH640ufI1ClA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# compute results\n",
    "results_eval = evaluator.evaluate(fctn, (x_train, y_train, s_train), (x_val, y_val, s_val), (x_test, y_test, s_test))"
   ],
   "metadata": {
    "id": "f11SsZoK1Mqh"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "cm = itemgetter(*('TN', 'FN', 'FP', 'TP'))(results_eval['train']['full']['stats'])\n",
    "metrics.ConfusionMatrixDisplay(np.array(cm).reshape(2, -1)).plot()\n",
    "plt.show()\n",
    "\n",
    "for j in ('full', 's = 0', 's = 1'):\n",
    "    fpr, tpr, auc = itemgetter(*('fpr', 'tpr', 'auc'))(results_eval['train'][j])\n",
    "    plt.plot(fpr, tpr, label=j + ': AUC = %0.4f' % auc)\n",
    "\n",
    "plt.plot(torch.linspace(0, 1, 100), torch.linspace(0, 1, 100), '--', label='rand')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "id": "xuU-IoCZ1bGK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot prediction (solid line is the prediction, dashed line is y = -x + 1)\n",
    "visualize_unfair_data((x_train, y_train, s_train), fctn.net, show_orig=True, domain=(-2, 2, -2, 2))\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "xBYYZhaTW34y"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Robust Training\n",
    "\n",
    "Here, we introduce robust training and compute the results."
   ],
   "metadata": {
    "id": "SMvpiyCWSEj-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# create linear network\n",
    "my_net = net.NN(lay.singleLayer(2, 1, act=act.identityActivation(), bias=True))\n",
    "\n",
    "# create objective function\n",
    "fctn_robust = ObjectiveFunctionLogisticRegression(my_net)\n",
    "\n",
    "# choose optimizer\n",
    "opt = torch.optim.Adam(fctn_robust.parameters(), lr=1e-2)\n",
    "\n",
    "# construct trainer\n",
    "trainer = TrainerSGD(opt, max_epochs=20)\n",
    "\n",
    "# train!\n",
    "results_train_robust = trainer.train(fctn_robust, (x_train, y_train, s_train), (x_val, y_val, s_val), (x_test, y_test, s_test), \n",
    "                                     verbose=True, robust=True)"
   ],
   "metadata": {
    "id": "0K9HeRp2SI5W"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# compute results\n",
    "results_eval_robust = evaluator.evaluate(fctn_robust, (x_train, y_train, s_train), (x_val, y_val, s_val), (x_test, y_test, s_test))"
   ],
   "metadata": {
    "id": "Tvh8F_joSR70"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot results\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "cm = itemgetter(*('TN', 'FN', 'FP', 'TP'))(results_eval_robust['train']['full']['stats'])\n",
    "metrics.ConfusionMatrixDisplay(np.array(cm).reshape(2, -1)).plot()\n",
    "plt.show()\n",
    "\n",
    "for j in ('full', 's = 0', 's = 1'):\n",
    "    fpr, tpr, auc = itemgetter(*('fpr', 'tpr', 'auc'))(results_eval_robust['train'][j])\n",
    "    plt.plot(fpr, tpr, label=j + ': AUC = %0.4f' % auc)\n",
    "\n",
    "plt.plot(torch.linspace(0, 1, 100), torch.linspace(0, 1, 100), '--', label='rand')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "boETNUf5SVt_"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# plot prediction (solid line is the prediction, dashed line is y = -x + 1)\n",
    "\n",
    "visualize_unfair_data((x_train, y_train, s_train), fctn_robust.net, show_orig=True, domain=(-2, 2, -2, 2))\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.xlabel('x1')\n",
    "plt.ylabel('x2')\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "93k4ccUSU_SB"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Fairness Comparison"
   ],
   "metadata": {
    "id": "eeox6Y2GraOl"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# comparison of fairness metrics\n",
    "from pprint import pprint\n",
    "print('STANDARD')\n",
    "pprint(results_eval['train']['fairness'])\n",
    "\n",
    "print('ROBUST')\n",
    "pprint(results_eval_robust['train']['fairness'])"
   ],
   "metadata": {
    "id": "mPeuzKo7rb7N"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
